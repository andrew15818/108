\documentclass{article}
\usepackage{fontspec}
\usepackage{xeCJK}
\usepackage[margin=1in]{geometry}
\usepackage[default]{sourcesanspro}
%apparently can only use this CJK font?
\setCJKmainfont{Noto Serif CJK TC}

%info
\title{Introduction To Artificial Intelligence: Homework 1 Report}
\author{Andres Ponce(彭思安)\\
0616110}
%%%

\begin{document}
\maketitle
\section{Introduction}
	The first assignment for the course involved a chess board, and placing a knight 
	on that board. Given a starting and ending position, how do we move the knight
	along the ``best" path from the start to the finish? Using several of the methods
	described in the textbook, the task focused on comparing the performance of each one.
	Some criteria may include: completeness, time and space complexity, among other general
	observations.
\subsection{Breadth-First-Search}
	The first algorithm to be implemented was the classic Breadth-First-Search. In general,
	this algorithm keeps a ``frontier" data structure where to-be-expanded nodes are stored.
	Every iteration, we pop a node from this set and examine its children. Since we can move 
	by either $(\pm1 , \pm2)$ or $(\pm2, \pm1)$, every node has a possible 8 children.

	In this implementation, we first check the validity of the specific child node(i.e. if it 
	has already been explored), and if we have not encountered it and is withing the board bounds, 
	we add it to the frontier list, implemented here by \texttt{std::list<Node*>}. If we already explored
	a node,then we already know it does not contain a shortest path, otherwise the algorithm would have
	halted already. 

	To store the individual nodes information, we use a special \texttt{struct Node}, 
	which essentially just stores the node's correspondent x and y values in the board. Then, a quick 
	hash function can turn the x and y values into the index in the node array.

	Breadth-First Search appears to not be the most efficient algorithm to use as is, unless we add
	some form of heuristic when we choose which nodes to explore. Our algorithm will eventually reach 
	the target node, however given a large enough board the time would likely be prohibitive. Since the
	branching factor is 8, since we can make 8 possible moves at every node, the worst-case time complexity
	is $O(d^{8})$, where $d$ is the depth of the solution path.
\subsection{Depth-First-Search}
	For depth-first-search(DFS), we first carry out a thread to the end, and as we are left without valid 
	states to move on to that we start backtracking up the chain. On average, it tends to be slower than
	BFS, since we can explore a large amount of nodes before getting to the target if the target is near
	the starting point. However, the \textit{memory} requirements are quite lower. This is because at any 
	point, only the nodes on the current search path are kept in memory -- the ones we have to search --
	rather than all the nodes at a given level such as BFS. 

	
	From some of the sample tests, DFS resulted in sometimes significantly longer search paths,
	since it would search for paths that lead to dead ends.

	Depending on the problem, DFS would probably not be the most ideal search algorithm. These two first
	algorithms usually have no heuristic to select nodes, so considerable time may be spent on nodes
	that ultimately have no bearing on the final result. Thus, uninformed algorithms in general might
	not be the wisest move. 
	
	An interesting experiment or topic for further discussion given enough time might be 
	to check the actual average difference between random points on the board. 
\subsection{Iterative Deepening Search}
	Iterative Deepening Search, sometimes referred to as \textit{Iterative Deepening Depth-First Search},
	attempts to combine the useful properties of BFS and DFS in one single algorithm. First, we set a limit
	on the depth of the solution, and call a depth-first search on the starting node. Thus, whenever we find
	the solution node, it should be done using the least amount of ndoes possible.

	Every time we don't find the solution node, we increase the limit and try again. This might result
	in the top nodes of the search tree being generated often, however the difference still turns out not
	to be too great, since most nodes reside in the lower levels of the search tree(assuming constant 
	branching factor). Even though the 
	asymptotic running time remains $O(b^{d})$ (same as BFS), the memory complexity is that of DFS $O(bd)$.
	For uninformed strategies with an unknown solution depth, IDS might be the best choice since like DFS
	for a finite space, it is guaranteed to find the solution becuase of the optimality property.

	For our implementation, we use a helper function, since we recursively call the helper function. When first
	entering the helper function, besides from just checking whehter we are at the target, we also have to check
	whether the limit has been reached. Other than that, we proceed in a very similar manner to DFS.

\subsection{A* Search}
	The a* algorithm usually turns out to be one of the most effective search algorithms, since we 
	use a heuristic to make a decision on which nodes to expand. The algorithm itself is relatively 
	straightforward: for every node, we keep track of three variables $f, g,$ and $h$.  $g$ is the 
	cost of getting to node $n$, while $h$ is the (estimated) cost of arriving at the solution node. 
	Then, for each node $f = g + h$. From the child nodes, we choose one that has a lower $f$ cost than
	its parent. 

	This is where the problems begin. Due to the unconventional movement of the knight in chess, 
	the program does not find the correct answer (and sometimes no answer at all) when we have to make
	a move away from the target, to a node that is actually \textit{farther away} from the target node
	than the one we are currently in right now. For example, the sample problem involves going from 
	$(0, 0)$ to $(2, 2)$. In this case, the program would move to $(2, 1)$ and then get stuck because
	the best move is actually one that is farther away from $(2, 2)$, i.e. a node with a higher $f$ value.

	Adapting this algorithm this situation would most definitely be an interesting research question. 
	A* remains widely used in many industries, from computer vision to video games, due to its efficiency
	and correctness. Since we only expand nodes that grant a better chance of arriving at a target, then
	we can overall expand fewer nodes.

	In this implemenation, if the target node can be reached directly without going to a further point, 
	then the algorithm will reach the target node with fewer expanded nodes than with an uninformed 
	search. 
\section{Results}
Maybe include a table with some of the nodes that we expanded, maybe with $(0, 2)$ and $(0, 7)$?
\section{Lessons}
	The biggest personal takeaway from this assignment was the sheer difference between informed and 
	uninformed searches. Spending valuable time expanding nodes that do not influence the final 
	result made the optimal path take considerably longer to compute. However, the problem was 
	solvable even with a relatively straightforward approach such as BFS and DFS. A* would take 
	considerably fewer nodes, usually less than 10 expansions. The total $f$ values would quickly 
	get very small,which means that the algorithm was moving in a targetetd manner towards the
	target node.

	The actual implementation of the algorithms also proved useful. Although I had already 
	implemented most of them in previous courses, this time finding a better approach to writing the
	code took more priority. 

	Some areas of interest include programs that play games based on the ideas of graph theory. When 
	we can model some of the ``best" moves in a game, it would be interesting to try to model the 
	games with such an approach. 
\end{document}
